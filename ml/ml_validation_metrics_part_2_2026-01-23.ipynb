{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07928fe3",
   "metadata": {},
   "source": [
    "### ML Validation Metrics. Part 2\n",
    "#### Date: 2026-01-23\n",
    "\n",
    "**Topics:**\n",
    "> 1. Causality\n",
    "> 2. Confounders\n",
    "> 3. Calibration\n",
    "> 4. LogLoss\n",
    "\n",
    "**Materials:**\n",
    "> 1. \n",
    "> 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff946ccc",
   "metadata": {},
   "source": [
    "#### Causality\n",
    "ML-модель вміє передбачати, але НЕ вміє доводити вплив дії\n",
    "\n",
    "**Prediction:** спрогнозувати proba для churn  \n",
    "**Intervention:** запрононувати знижку \n",
    "\n",
    "##### prediction != intervention\n",
    "\n",
    "ML-модель виявляє:\n",
    "> транзакції з високою ймовірністю fraud\n",
    "\n",
    "Помилковий висновок:\n",
    "> Якщо ми їх заблокуємо — ми зменшимо fraud\n",
    "\n",
    "Модель не знає, що було б:\n",
    "> якби ми не заблокували \\\n",
    "> якби ми заблокували інакше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a5d4e",
   "metadata": {},
   "source": [
    "#### Confounders\n",
    "\n",
    "Фактор, який впливає і на ознаку, і на результат\n",
    "та створює хибне враження причинності\n",
    "\n",
    "\n",
    "**Спостереження з даних:**\n",
    "> користувачі зі знижками частіше йдуть\n",
    "\n",
    "**Хибний висновок:**\n",
    "> Знижки збільшують churn\n",
    "\n",
    "**Реальність:**\n",
    "> знижки дають тим, хто вже хотів піти\n",
    "\n",
    "намір піти — confounder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d463c",
   "metadata": {},
   "source": [
    "#### Calibration \n",
    "\n",
    "**Модель видає:** p = 0.8, 80% імовірність -> можна діяти впевнено\n",
    "\n",
    "> серед усіх прогнозів p~0.8 \\\n",
    "> реально fraud трапляється у 50% випадків \\\n",
    "> модель переоцінює ризик\n",
    "\n",
    "\n",
    "Якщо модель каже p = 0.3,\n",
    "то подія відбувається приблизно у 30% випадків\n",
    "\n",
    "> бізнес приймає рішення по порогах \\\n",
    "> пороги базуються на p \\\n",
    "> якщо p бреше -> рішення хаотичні"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529a1ae",
   "metadata": {},
   "source": [
    "##### LogLoss - індекатор калібровки\n",
    "наскільки сильно модель карається за впевнені, але неправильні прогнози\n",
    "\n",
    "Якщо дві моделі мають схожий PR-AUC, але одна має нижчий LogLoss — її ймовірностям можна більше довіряти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb034229",
   "metadata": {},
   "source": [
    "> ML -> оцінює ризик \\\n",
    "> Calibration -> робить ризик чесним \\\n",
    "> Policy -> перетворює ризик у дію \\\n",
    "> Causality -> не дозволяє брехати про ефект\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8530097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca9a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top missing columns:\n",
      "Time    0.0\n",
      "V1      0.0\n",
      "V2      0.0\n",
      "V3      0.0\n",
      "V4      0.0\n",
      "V5      0.0\n",
      "V6      0.0\n",
      "V7      0.0\n",
      "V8      0.0\n",
      "V9      0.0\n",
      "dtype: float64\n",
      "\n",
      "Class counts:\n",
      " Class\n",
      "'0'    284315\n",
      "'1'       492\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class ratio:\n",
      " Class\n",
      "'0'    0.998273\n",
      "'1'    0.001727\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "missing_rate = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop missing columns:\")\n",
    "print(missing_rate.head(10))\n",
    "\n",
    "\n",
    "class_counts = df[\"Class\"].value_counts()\n",
    "class_ratio = df[\"Class\"].value_counts(normalize=True)\n",
    "\n",
    "print(\"\\nClass counts:\\n\", class_counts)\n",
    "print(\"\\nClass ratio:\\n\", class_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d90c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651ec9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be8602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87497108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(y_true: pd.Series, y_proba: np.ndarray, k_frac: float) -> float:\n",
    "    n = len(y_true)\n",
    "    k = max(1, int(n * k_frac))\n",
    "\n",
    "    top_idx = np.argsort(y_proba)[::-1][:k]\n",
    "    fraud_in_top = y_true.iloc[top_idx].sum()\n",
    "\n",
    "    total_fraud = y_true.sum()\n",
    "\n",
    "    return fraud_in_top / max(1, total_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af96725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(y_true: pd.Series, y_proba: np.ndarray, threshold: float, k_fracs=(0.001, 0.005, 0.01)) -> dict:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    out = {\n",
    "        \"threshold\": threshold,\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"ROC-AUC\": roc_auc_score(y_true, y_proba),\n",
    "        \"PR-AUC\": average_precision_score(y_true, y_proba),\n",
    "        \"LogLoss\": log_loss(y_true, y_proba, labels=[0, 1]),\n",
    "        \"ConfusionMatrix\": confusion_matrix(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    for kf in k_fracs:\n",
    "        out[f\"Recall@{kf*100:.2f}%\"] = recall_at_k(y_true, y_proba, k_frac=kf)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4f05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(title: str, metrics: dict):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(title)\n",
    "    print(\"=\"*60)\n",
    "    for k, v in metrics.items():\n",
    "        if k == \"ConfusionMatrix\":\n",
    "            continue\n",
    "        print(f\"{k:>14}: {v}\")\n",
    "\n",
    "    cm = metrics[\"ConfusionMatrix\"]\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"\\nConfusion Matrix [[TN FP],[FN TP]]:\")\n",
    "    print(cm)\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aeb7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LogReg threshold = 0.5\n",
      "============================================================\n",
      "     threshold: 0.5\n",
      "     Precision: 0.06097560975609756\n",
      "        Recall: 0.9183673469387755\n",
      "            F1: 0.11435832274459974\n",
      "       ROC-AUC: 0.9720834996210077\n",
      "        PR-AUC: 0.7189705771419241\n",
      "       LogLoss: 0.11219568508756639\n",
      "  Recall@0.10%: 0.45918367346938777\n",
      "  Recall@0.50%: 0.8877551020408163\n",
      "  Recall@1.00%: 0.8979591836734694\n",
      "\n",
      "Confusion Matrix [[TN FP],[FN TP]]:\n",
      "[[55478  1386]\n",
      " [    8    90]]\n",
      "TN=55478, FP=1386, FN=8, TP=90\n"
     ]
    }
   ],
   "source": [
    "lr = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),  \n",
    "    (\"model\", LogisticRegression(\n",
    "        class_weight = \"balanced\",   \n",
    "        max_iter = 2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "proba_lr = lr.predict_proba(X_test)[:, 1]\n",
    "res_lr_05 = evaluate_all(y_test, proba_lr, threshold=0.5)\n",
    "print_eval(\"LogReg threshold = 0.5\", res_lr_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7490209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RandomForest threshold = 0.5\n",
      "============================================================\n",
      "     threshold: 0.5\n",
      "     Precision: 0.961038961038961\n",
      "        Recall: 0.7551020408163265\n",
      "            F1: 0.8457142857142858\n",
      "       ROC-AUC: 0.9561622324084388\n",
      "        PR-AUC: 0.8635382284721764\n",
      "       LogLoss: 0.00631719530271903\n",
      "  Recall@0.10%: 0.5510204081632653\n",
      "  Recall@0.50%: 0.8979591836734694\n",
      "  Recall@1.00%: 0.8979591836734694\n",
      "\n",
      "Confusion Matrix [[TN FP],[FN TP]]:\n",
      "[[56861     3]\n",
      " [   24    74]]\n",
      "TN=56861, FP=3, FN=24, TP=74\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    random_state = RANDOM_STATE,\n",
    "    n_jobs = -1,\n",
    "    class_weight = \"balanced_subsample\"  \n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "res_rf_05 = evaluate_all(y_test, proba_rf, threshold=0.5)\n",
    "print_eval(\"RandomForest threshold = 0.5\", res_rf_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab02505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m      9\u001b[39m cv = StratifiedKFold(n_splits=\u001b[32m3\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=RANDOM_STATE)\n\u001b[32m     11\u001b[39m search = RandomizedSearchCV(\n\u001b[32m     12\u001b[39m     estimator=RandomForestClassifier(\n\u001b[32m     13\u001b[39m         random_state=RANDOM_STATE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     random_state=RANDOM_STATE\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"max_depth\": [None, 8, 12, 16, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    ),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                      \n",
    "    scoring=\"average_precision\",     \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = search.best_estimator_\n",
    "print(\"\\nBest params:\", search.best_params_)\n",
    "print(\"Best CV PR-AUC:\", search.best_score_)\n",
    "\n",
    "proba_rf_tuned = rf_tuned.predict_proba(X_test)[:, 1]\n",
    "res_rf_tuned_05 = evaluate_all(y_test, proba_rf_tuned, threshold=0.5)\n",
    "print_eval(\"RandomForest (tuned) @ threshold=0.5\", res_rf_tuned_05)\n",
    "\n",
    "print(\"\\nRecall@0.5% (RF tuned):\", recall_at_k(y_test, proba_rf_tuned, 0.005))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c848c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cal = CalibratedClassifierCV(\n",
    "    estimator=rf_tuned,   \n",
    "    method=\"isotonic\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "rf_cal.fit(X_train, y_train)\n",
    "proba_rf_cal = rf_cal.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "res_before = evaluate_all(y_test, proba_rf_tuned, threshold=0.2)\n",
    "res_after  = evaluate_all(y_test, proba_rf_cal, threshold=0.2)\n",
    "\n",
    "print_eval(\"RF tuned BEFORE calibration  threshold=0.2\", res_before)\n",
    "print_eval(\"RF tuned AFTER  calibration  threshold=0.2\", res_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2e242e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proba_rf_tuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 18\u001b[0m plot_calibration(y_test, \u001b[43mproba_rf_tuned\u001b[49m, proba_rf_cal, n_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proba_rf_tuned' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_calibration(y_true, prob_uncal, prob_cal, n_bins=10):\n",
    "    t_uncal, p_uncal = calibration_curve(y_true, prob_uncal, n_bins=n_bins, strategy=\"uniform\")\n",
    "    t_cal,   p_cal   = calibration_curve(y_true, prob_cal,   n_bins=n_bins, strategy=\"uniform\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "\n",
    "    plt.plot(p_uncal, t_uncal, marker=\"o\", label=\"Before calibration\")\n",
    "\n",
    "    plt.plot(p_cal, t_cal, marker=\"o\", label=\"After calibration\")\n",
    "\n",
    "    plt.xlabel(\"Середня передбачена ймовірність (p)\")\n",
    "    plt.ylabel(\"Реальна частота fraud\")\n",
    "    plt.title(\"Calibration curve (reliability)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_calibration(y_test, proba_rf_tuned, proba_rf_cal, n_bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e071b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_policy(p: float) -> str:\n",
    "    if p >= 0.90:\n",
    "        return \"AUTO_BLOCK_or_2FA\"\n",
    "    elif p >= 0.40:\n",
    "        return \"MANUAL_REVIEW\"\n",
    "    else:\n",
    "        return \"ALLOW\"\n",
    "\n",
    "actions = pd.Series(proba_rf_cal).apply(fraud_policy)\n",
    "\n",
    "print(\"\\nAction distribution:\")\n",
    "print(actions.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
